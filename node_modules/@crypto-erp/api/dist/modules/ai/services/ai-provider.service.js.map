{"version":3,"sources":["../../../../src/modules/ai/services/ai-provider.service.ts"],"sourcesContent":["import { Injectable, Logger, OnModuleInit } from '@nestjs/common';\nimport { ConfigService } from '@nestjs/config';\n\n/**\n * AI Provider Service con Fallback\n * Gestiona múltiples proveedores de LLM con failover automático\n * Orden de prioridad: Anthropic → OpenAI → Ollama (local)\n */\n\nexport interface ChatMessage {\n  role: 'user' | 'assistant' | 'system';\n  content: string;\n}\n\nexport interface AIResponse {\n  content: string;\n  provider: string;\n  model: string;\n  tokensUsed?: number;\n  latencyMs: number;\n}\n\nexport interface ProviderConfig {\n  name: string;\n  priority: number;\n  enabled: boolean;\n  apiKey?: string;\n  baseUrl?: string;\n  model: string;\n  maxTokens: number;\n}\n\n@Injectable()\nexport class AIProviderService implements OnModuleInit {\n  private readonly logger = new Logger(AIProviderService.name);\n  private providers: ProviderConfig[] = [];\n\n  constructor(private readonly configService: ConfigService) {}\n\n  async onModuleInit() {\n    this.initializeProviders();\n    this.logger.log(\n      `AI providers initialized: ${this.providers.filter((p) => p.enabled).map((p) => p.name).join(', ')}`,\n    );\n  }\n\n  private initializeProviders() {\n    const anthropicKey = this.configService.get<string>('ANTHROPIC_API_KEY');\n    const openaiKey = this.configService.get<string>('OPENAI_API_KEY');\n    const ollamaUrl =\n      this.configService.get<string>('OLLAMA_URL') || 'http://localhost:11434';\n\n    this.providers = [\n      {\n        name: 'anthropic',\n        priority: 1,\n        enabled: !!anthropicKey,\n        apiKey: anthropicKey,\n        model: 'claude-3-haiku-20240307',\n        maxTokens: 4096,\n      },\n      {\n        name: 'openai',\n        priority: 2,\n        enabled: !!openaiKey,\n        apiKey: openaiKey,\n        model: 'gpt-4o-mini',\n        maxTokens: 4096,\n      },\n      {\n        name: 'ollama',\n        priority: 3,\n        enabled: true, // Siempre disponible como fallback local\n        baseUrl: ollamaUrl,\n        model: 'llama3.2:3b',\n        maxTokens: 2048,\n      },\n    ].sort((a, b) => a.priority - b.priority);\n  }\n\n  /**\n   * Envía un mensaje al LLM con fallback automático\n   */\n  async chat(\n    messages: ChatMessage[],\n    options: {\n      systemPrompt?: string;\n      maxTokens?: number;\n      temperature?: number;\n      preferredProvider?: string;\n    } = {},\n  ): Promise<AIResponse> {\n    const enabledProviders = this.providers.filter((p) => p.enabled);\n\n    // Si hay preferencia, mover ese provider al principio\n    if (options.preferredProvider) {\n      const preferred = enabledProviders.find(\n        (p) => p.name === options.preferredProvider,\n      );\n      if (preferred) {\n        const others = enabledProviders.filter(\n          (p) => p.name !== options.preferredProvider,\n        );\n        enabledProviders.splice(0, enabledProviders.length, preferred, ...others);\n      }\n    }\n\n    let lastError: Error | null = null;\n\n    for (const provider of enabledProviders) {\n      try {\n        const startTime = Date.now();\n        const response = await this.callProvider(provider, messages, options);\n        const latencyMs = Date.now() - startTime;\n\n        return {\n          ...response,\n          provider: provider.name,\n          model: provider.model,\n          latencyMs,\n        };\n      } catch (error) {\n        lastError = error as Error;\n        this.logger.warn(\n          `Provider ${provider.name} failed: ${lastError.message}`,\n        );\n      }\n    }\n\n    throw new Error(\n      `All AI providers failed. Last error: ${lastError?.message || 'Unknown'}`,\n    );\n  }\n\n  private async callProvider(\n    provider: ProviderConfig,\n    messages: ChatMessage[],\n    options: {\n      systemPrompt?: string;\n      maxTokens?: number;\n      temperature?: number;\n    },\n  ): Promise<{ content: string; tokensUsed?: number }> {\n    switch (provider.name) {\n      case 'anthropic':\n        return this.callAnthropic(provider, messages, options);\n      case 'openai':\n        return this.callOpenAI(provider, messages, options);\n      case 'ollama':\n        return this.callOllama(provider, messages, options);\n      default:\n        throw new Error(`Unknown provider: ${provider.name}`);\n    }\n  }\n\n  private async callAnthropic(\n    provider: ProviderConfig,\n    messages: ChatMessage[],\n    options: {\n      systemPrompt?: string;\n      maxTokens?: number;\n      temperature?: number;\n    },\n  ): Promise<{ content: string; tokensUsed?: number }> {\n    const response = await fetch('https://api.anthropic.com/v1/messages', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'x-api-key': provider.apiKey!,\n        'anthropic-version': '2023-06-01',\n      },\n      body: JSON.stringify({\n        model: provider.model,\n        max_tokens: options.maxTokens || provider.maxTokens,\n        system: options.systemPrompt || this.getDefaultSystemPrompt(),\n        messages: messages.map((m) => ({\n          role: m.role === 'system' ? 'user' : m.role,\n          content: m.content,\n        })),\n        temperature: options.temperature || 0.7,\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      throw new Error(`Anthropic API error: ${response.status} - ${error}`);\n    }\n\n    const data = (await response.json()) as {\n      content: Array<{ text: string }>;\n      usage?: { input_tokens: number; output_tokens: number };\n    };\n\n    return {\n      content: data.content[0]?.text || '',\n      tokensUsed: data.usage\n        ? data.usage.input_tokens + data.usage.output_tokens\n        : undefined,\n    };\n  }\n\n  private async callOpenAI(\n    provider: ProviderConfig,\n    messages: ChatMessage[],\n    options: {\n      systemPrompt?: string;\n      maxTokens?: number;\n      temperature?: number;\n    },\n  ): Promise<{ content: string; tokensUsed?: number }> {\n    const allMessages: Array<{ role: string; content: string }> = [];\n\n    if (options.systemPrompt) {\n      allMessages.push({ role: 'system', content: options.systemPrompt });\n    } else {\n      allMessages.push({ role: 'system', content: this.getDefaultSystemPrompt() });\n    }\n\n    allMessages.push(\n      ...messages.map((m) => ({\n        role: m.role,\n        content: m.content,\n      })),\n    );\n\n    const response = await fetch('https://api.openai.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        Authorization: `Bearer ${provider.apiKey}`,\n      },\n      body: JSON.stringify({\n        model: provider.model,\n        messages: allMessages,\n        max_tokens: options.maxTokens || provider.maxTokens,\n        temperature: options.temperature || 0.7,\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      throw new Error(`OpenAI API error: ${response.status} - ${error}`);\n    }\n\n    const data = (await response.json()) as {\n      choices: Array<{ message: { content: string } }>;\n      usage?: { total_tokens: number };\n    };\n\n    return {\n      content: data.choices[0]?.message?.content || '',\n      tokensUsed: data.usage?.total_tokens,\n    };\n  }\n\n  private async callOllama(\n    provider: ProviderConfig,\n    messages: ChatMessage[],\n    options: {\n      systemPrompt?: string;\n      maxTokens?: number;\n      temperature?: number;\n    },\n  ): Promise<{ content: string; tokensUsed?: number }> {\n    const allMessages: Array<{ role: string; content: string }> = [];\n\n    if (options.systemPrompt) {\n      allMessages.push({ role: 'system', content: options.systemPrompt });\n    } else {\n      allMessages.push({ role: 'system', content: this.getDefaultSystemPrompt() });\n    }\n\n    allMessages.push(\n      ...messages.map((m) => ({\n        role: m.role,\n        content: m.content,\n      })),\n    );\n\n    try {\n      const response = await fetch(`${provider.baseUrl}/api/chat`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          model: provider.model,\n          messages: allMessages,\n          stream: false,\n          options: {\n            num_predict: options.maxTokens || provider.maxTokens,\n            temperature: options.temperature || 0.7,\n          },\n        }),\n      });\n\n      if (!response.ok) {\n        throw new Error(`Ollama API error: ${response.status}`);\n      }\n\n      const data = (await response.json()) as {\n        message: { content: string };\n        eval_count?: number;\n        prompt_eval_count?: number;\n      };\n\n      return {\n        content: data.message?.content || '',\n        tokensUsed: data.eval_count\n          ? data.eval_count + (data.prompt_eval_count || 0)\n          : undefined,\n      };\n    } catch (error) {\n      // Ollama puede no estar corriendo\n      throw new Error(\n        `Ollama not available at ${provider.baseUrl}: ${(error as Error).message}`,\n      );\n    }\n  }\n\n  private getDefaultSystemPrompt(): string {\n    return `Eres un asistente experto en contabilidad, fiscalidad española y criptomonedas.\nEspecializaciones:\n- Normativa fiscal española (AEAT, IVA, IRPF)\n- Contabilidad según Plan General Contable (PGC)\n- Fiscalidad de criptomonedas (FIFO, Modelo 721)\n- Sistema Verifactu de facturación electrónica\n\nResponde de forma concisa y profesional en español.\nSi no estás seguro de algo, indícalo claramente.`;\n  }\n\n  /**\n   * Obtiene el estado de los proveedores\n   */\n  getProvidersStatus(): Array<{\n    name: string;\n    enabled: boolean;\n    priority: number;\n    model: string;\n  }> {\n    return this.providers.map((p) => ({\n      name: p.name,\n      enabled: p.enabled,\n      priority: p.priority,\n      model: p.model,\n    }));\n  }\n\n  /**\n   * Verifica la disponibilidad de un provider\n   */\n  async checkProviderHealth(providerName: string): Promise<boolean> {\n    const provider = this.providers.find((p) => p.name === providerName);\n    if (!provider || !provider.enabled) {\n      return false;\n    }\n\n    try {\n      await this.callProvider(\n        provider,\n        [{ role: 'user', content: 'ping' }],\n        { maxTokens: 10 },\n      );\n      return true;\n    } catch {\n      return false;\n    }\n  }\n}\n"],"names":["AIProviderService","onModuleInit","initializeProviders","logger","log","providers","filter","p","enabled","map","name","join","anthropicKey","configService","get","openaiKey","ollamaUrl","priority","apiKey","model","maxTokens","baseUrl","sort","a","b","chat","messages","options","enabledProviders","preferredProvider","preferred","find","others","splice","length","lastError","provider","startTime","Date","now","response","callProvider","latencyMs","error","warn","message","Error","callAnthropic","callOpenAI","callOllama","fetch","method","headers","body","JSON","stringify","max_tokens","system","systemPrompt","getDefaultSystemPrompt","m","role","content","temperature","ok","text","status","data","json","tokensUsed","usage","input_tokens","output_tokens","undefined","allMessages","push","Authorization","choices","total_tokens","stream","num_predict","eval_count","prompt_eval_count","getProvidersStatus","checkProviderHealth","providerName","Logger"],"mappings":";;;;+BAiCaA;;;eAAAA;;;wBAjCoC;wBACnB;;;;;;;;;;AAgCvB,IAAA,AAAMA,oBAAN,MAAMA;IAMX,MAAMC,eAAe;QACnB,IAAI,CAACC,mBAAmB;QACxB,IAAI,CAACC,MAAM,CAACC,GAAG,CACb,CAAC,0BAA0B,EAAE,IAAI,CAACC,SAAS,CAACC,MAAM,CAAC,CAACC,IAAMA,EAAEC,OAAO,EAAEC,GAAG,CAAC,CAACF,IAAMA,EAAEG,IAAI,EAAEC,IAAI,CAAC,OAAO;IAExG;IAEQT,sBAAsB;QAC5B,MAAMU,eAAe,IAAI,CAACC,aAAa,CAACC,GAAG,CAAS;QACpD,MAAMC,YAAY,IAAI,CAACF,aAAa,CAACC,GAAG,CAAS;QACjD,MAAME,YACJ,IAAI,CAACH,aAAa,CAACC,GAAG,CAAS,iBAAiB;QAElD,IAAI,CAACT,SAAS,GAAG;YACf;gBACEK,MAAM;gBACNO,UAAU;gBACVT,SAAS,CAAC,CAACI;gBACXM,QAAQN;gBACRO,OAAO;gBACPC,WAAW;YACb;YACA;gBACEV,MAAM;gBACNO,UAAU;gBACVT,SAAS,CAAC,CAACO;gBACXG,QAAQH;gBACRI,OAAO;gBACPC,WAAW;YACb;YACA;gBACEV,MAAM;gBACNO,UAAU;gBACVT,SAAS;gBACTa,SAASL;gBACTG,OAAO;gBACPC,WAAW;YACb;SACD,CAACE,IAAI,CAAC,CAACC,GAAGC,IAAMD,EAAEN,QAAQ,GAAGO,EAAEP,QAAQ;IAC1C;IAEA;;GAEC,GACD,MAAMQ,KACJC,QAAuB,EACvBC,UAKI,CAAC,CAAC,EACe;QACrB,MAAMC,mBAAmB,IAAI,CAACvB,SAAS,CAACC,MAAM,CAAC,CAACC,IAAMA,EAAEC,OAAO;QAE/D,sDAAsD;QACtD,IAAImB,QAAQE,iBAAiB,EAAE;YAC7B,MAAMC,YAAYF,iBAAiBG,IAAI,CACrC,CAACxB,IAAMA,EAAEG,IAAI,KAAKiB,QAAQE,iBAAiB;YAE7C,IAAIC,WAAW;gBACb,MAAME,SAASJ,iBAAiBtB,MAAM,CACpC,CAACC,IAAMA,EAAEG,IAAI,KAAKiB,QAAQE,iBAAiB;gBAE7CD,iBAAiBK,MAAM,CAAC,GAAGL,iBAAiBM,MAAM,EAAEJ,cAAcE;YACpE;QACF;QAEA,IAAIG,YAA0B;QAE9B,KAAK,MAAMC,YAAYR,iBAAkB;YACvC,IAAI;gBACF,MAAMS,YAAYC,KAAKC,GAAG;gBAC1B,MAAMC,WAAW,MAAM,IAAI,CAACC,YAAY,CAACL,UAAUV,UAAUC;gBAC7D,MAAMe,YAAYJ,KAAKC,GAAG,KAAKF;gBAE/B,OAAO;oBACL,GAAGG,QAAQ;oBACXJ,UAAUA,SAAS1B,IAAI;oBACvBS,OAAOiB,SAASjB,KAAK;oBACrBuB;gBACF;YACF,EAAE,OAAOC,OAAO;gBACdR,YAAYQ;gBACZ,IAAI,CAACxC,MAAM,CAACyC,IAAI,CACd,CAAC,SAAS,EAAER,SAAS1B,IAAI,CAAC,SAAS,EAAEyB,UAAUU,OAAO,EAAE;YAE5D;QACF;QAEA,MAAM,IAAIC,MACR,CAAC,qCAAqC,EAAEX,WAAWU,WAAW,WAAW;IAE7E;IAEA,MAAcJ,aACZL,QAAwB,EACxBV,QAAuB,EACvBC,OAIC,EACkD;QACnD,OAAQS,SAAS1B,IAAI;YACnB,KAAK;gBACH,OAAO,IAAI,CAACqC,aAAa,CAACX,UAAUV,UAAUC;YAChD,KAAK;gBACH,OAAO,IAAI,CAACqB,UAAU,CAACZ,UAAUV,UAAUC;YAC7C,KAAK;gBACH,OAAO,IAAI,CAACsB,UAAU,CAACb,UAAUV,UAAUC;YAC7C;gBACE,MAAM,IAAImB,MAAM,CAAC,kBAAkB,EAAEV,SAAS1B,IAAI,EAAE;QACxD;IACF;IAEA,MAAcqC,cACZX,QAAwB,EACxBV,QAAuB,EACvBC,OAIC,EACkD;QACnD,MAAMa,WAAW,MAAMU,MAAM,yCAAyC;YACpEC,QAAQ;YACRC,SAAS;gBACP,gBAAgB;gBAChB,aAAahB,SAASlB,MAAM;gBAC5B,qBAAqB;YACvB;YACAmC,MAAMC,KAAKC,SAAS,CAAC;gBACnBpC,OAAOiB,SAASjB,KAAK;gBACrBqC,YAAY7B,QAAQP,SAAS,IAAIgB,SAAShB,SAAS;gBACnDqC,QAAQ9B,QAAQ+B,YAAY,IAAI,IAAI,CAACC,sBAAsB;gBAC3DjC,UAAUA,SAASjB,GAAG,CAAC,CAACmD,IAAO,CAAA;wBAC7BC,MAAMD,EAAEC,IAAI,KAAK,WAAW,SAASD,EAAEC,IAAI;wBAC3CC,SAASF,EAAEE,OAAO;oBACpB,CAAA;gBACAC,aAAapC,QAAQoC,WAAW,IAAI;YACtC;QACF;QAEA,IAAI,CAACvB,SAASwB,EAAE,EAAE;YAChB,MAAMrB,QAAQ,MAAMH,SAASyB,IAAI;YACjC,MAAM,IAAInB,MAAM,CAAC,qBAAqB,EAAEN,SAAS0B,MAAM,CAAC,GAAG,EAAEvB,OAAO;QACtE;QAEA,MAAMwB,OAAQ,MAAM3B,SAAS4B,IAAI;QAKjC,OAAO;YACLN,SAASK,KAAKL,OAAO,CAAC,EAAE,EAAEG,QAAQ;YAClCI,YAAYF,KAAKG,KAAK,GAClBH,KAAKG,KAAK,CAACC,YAAY,GAAGJ,KAAKG,KAAK,CAACE,aAAa,GAClDC;QACN;IACF;IAEA,MAAczB,WACZZ,QAAwB,EACxBV,QAAuB,EACvBC,OAIC,EACkD;QACnD,MAAM+C,cAAwD,EAAE;QAEhE,IAAI/C,QAAQ+B,YAAY,EAAE;YACxBgB,YAAYC,IAAI,CAAC;gBAAEd,MAAM;gBAAUC,SAASnC,QAAQ+B,YAAY;YAAC;QACnE,OAAO;YACLgB,YAAYC,IAAI,CAAC;gBAAEd,MAAM;gBAAUC,SAAS,IAAI,CAACH,sBAAsB;YAAG;QAC5E;QAEAe,YAAYC,IAAI,IACXjD,SAASjB,GAAG,CAAC,CAACmD,IAAO,CAAA;gBACtBC,MAAMD,EAAEC,IAAI;gBACZC,SAASF,EAAEE,OAAO;YACpB,CAAA;QAGF,MAAMtB,WAAW,MAAMU,MAAM,8CAA8C;YACzEC,QAAQ;YACRC,SAAS;gBACP,gBAAgB;gBAChBwB,eAAe,CAAC,OAAO,EAAExC,SAASlB,MAAM,EAAE;YAC5C;YACAmC,MAAMC,KAAKC,SAAS,CAAC;gBACnBpC,OAAOiB,SAASjB,KAAK;gBACrBO,UAAUgD;gBACVlB,YAAY7B,QAAQP,SAAS,IAAIgB,SAAShB,SAAS;gBACnD2C,aAAapC,QAAQoC,WAAW,IAAI;YACtC;QACF;QAEA,IAAI,CAACvB,SAASwB,EAAE,EAAE;YAChB,MAAMrB,QAAQ,MAAMH,SAASyB,IAAI;YACjC,MAAM,IAAInB,MAAM,CAAC,kBAAkB,EAAEN,SAAS0B,MAAM,CAAC,GAAG,EAAEvB,OAAO;QACnE;QAEA,MAAMwB,OAAQ,MAAM3B,SAAS4B,IAAI;QAKjC,OAAO;YACLN,SAASK,KAAKU,OAAO,CAAC,EAAE,EAAEhC,SAASiB,WAAW;YAC9CO,YAAYF,KAAKG,KAAK,EAAEQ;QAC1B;IACF;IAEA,MAAc7B,WACZb,QAAwB,EACxBV,QAAuB,EACvBC,OAIC,EACkD;QACnD,MAAM+C,cAAwD,EAAE;QAEhE,IAAI/C,QAAQ+B,YAAY,EAAE;YACxBgB,YAAYC,IAAI,CAAC;gBAAEd,MAAM;gBAAUC,SAASnC,QAAQ+B,YAAY;YAAC;QACnE,OAAO;YACLgB,YAAYC,IAAI,CAAC;gBAAEd,MAAM;gBAAUC,SAAS,IAAI,CAACH,sBAAsB;YAAG;QAC5E;QAEAe,YAAYC,IAAI,IACXjD,SAASjB,GAAG,CAAC,CAACmD,IAAO,CAAA;gBACtBC,MAAMD,EAAEC,IAAI;gBACZC,SAASF,EAAEE,OAAO;YACpB,CAAA;QAGF,IAAI;YACF,MAAMtB,WAAW,MAAMU,MAAM,GAAGd,SAASf,OAAO,CAAC,SAAS,CAAC,EAAE;gBAC3D8B,QAAQ;gBACRC,SAAS;oBACP,gBAAgB;gBAClB;gBACAC,MAAMC,KAAKC,SAAS,CAAC;oBACnBpC,OAAOiB,SAASjB,KAAK;oBACrBO,UAAUgD;oBACVK,QAAQ;oBACRpD,SAAS;wBACPqD,aAAarD,QAAQP,SAAS,IAAIgB,SAAShB,SAAS;wBACpD2C,aAAapC,QAAQoC,WAAW,IAAI;oBACtC;gBACF;YACF;YAEA,IAAI,CAACvB,SAASwB,EAAE,EAAE;gBAChB,MAAM,IAAIlB,MAAM,CAAC,kBAAkB,EAAEN,SAAS0B,MAAM,EAAE;YACxD;YAEA,MAAMC,OAAQ,MAAM3B,SAAS4B,IAAI;YAMjC,OAAO;gBACLN,SAASK,KAAKtB,OAAO,EAAEiB,WAAW;gBAClCO,YAAYF,KAAKc,UAAU,GACvBd,KAAKc,UAAU,GAAId,CAAAA,KAAKe,iBAAiB,IAAI,CAAA,IAC7CT;YACN;QACF,EAAE,OAAO9B,OAAO;YACd,kCAAkC;YAClC,MAAM,IAAIG,MACR,CAAC,wBAAwB,EAAEV,SAASf,OAAO,CAAC,EAAE,EAAE,AAACsB,MAAgBE,OAAO,EAAE;QAE9E;IACF;IAEQc,yBAAiC;QACvC,OAAO,CAAC;;;;;;;;gDAQoC,CAAC;IAC/C;IAEA;;GAEC,GACDwB,qBAKG;QACD,OAAO,IAAI,CAAC9E,SAAS,CAACI,GAAG,CAAC,CAACF,IAAO,CAAA;gBAChCG,MAAMH,EAAEG,IAAI;gBACZF,SAASD,EAAEC,OAAO;gBAClBS,UAAUV,EAAEU,QAAQ;gBACpBE,OAAOZ,EAAEY,KAAK;YAChB,CAAA;IACF;IAEA;;GAEC,GACD,MAAMiE,oBAAoBC,YAAoB,EAAoB;QAChE,MAAMjD,WAAW,IAAI,CAAC/B,SAAS,CAAC0B,IAAI,CAAC,CAACxB,IAAMA,EAAEG,IAAI,KAAK2E;QACvD,IAAI,CAACjD,YAAY,CAACA,SAAS5B,OAAO,EAAE;YAClC,OAAO;QACT;QAEA,IAAI;YACF,MAAM,IAAI,CAACiC,YAAY,CACrBL,UACA;gBAAC;oBAAEyB,MAAM;oBAAQC,SAAS;gBAAO;aAAE,EACnC;gBAAE1C,WAAW;YAAG;YAElB,OAAO;QACT,EAAE,OAAM;YACN,OAAO;QACT;IACF;IA3UA,YAAY,AAAiBP,aAA4B,CAAE;aAA9BA,gBAAAA;aAHZV,SAAS,IAAImF,cAAM,CAACtF,kBAAkBU,IAAI;aACnDL,YAA8B,EAAE;IAEoB;AA4U9D"}